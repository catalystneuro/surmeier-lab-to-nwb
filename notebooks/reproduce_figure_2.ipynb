{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header_cell",
   "metadata": {},
   "source": [
    "# Reproducing Figure 2G-H: oEPSC Analysis\n",
    "\n",
    "This notebook reproduces Figure 2G-H from **Zhai et al. 2025** comparing optogenetically-evoked postsynaptic currents (oEPSCs) between OffState and OnState conditions in a Parkinson's disease model.\n",
    "\n",
    "**Dataset**: DANDI:001538 - State-dependent modulation of spiny projection neurons controls levodopa-induced dyskinesia\n",
    "\n",
    "**Analysis approach**:\n",
    "- **Figure 2G**: Cumulative distribution of all individual oEPSC events\n",
    "- **Figure 2H**: Box plot comparing mean event amplitudes per experimental session\n",
    "- **Event detection**: MAD-based noise estimation with ±5SD threshold\n",
    "- **Conditions**: OffState (control) vs OnState (L-DOPA treated)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup_header",
   "metadata": {},
   "source": [
    "## Setup and Data Loading\n",
    "\n",
    "### Import Libraries and Configure Plotting Style\n",
    "\n",
    "We use the same plotting parameters as the original publication to ensure visual consistency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports_cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import remfile\n",
    "import seaborn as sns\n",
    "from dandi.dandiapi import DandiAPIClient\n",
    "from dotenv import load_dotenv\n",
    "from pynwb import NWBHDF5IO\n",
    "from scipy import stats\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Set plotting style to match paper\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"Set2\")\n",
    "\n",
    "def setup_figure_style():\n",
    "    \"\"\"Setup matplotlib parameters to match paper style\"\"\"\n",
    "    plt.rcParams.update({\n",
    "        'font.size': 8,\n",
    "        'axes.titlesize': 10,\n",
    "        'axes.labelsize': 9,\n",
    "        'xtick.labelsize': 8,\n",
    "        'ytick.labelsize': 8,\n",
    "        'legend.fontsize': 8,\n",
    "        'figure.titlesize': 12,\n",
    "        'axes.linewidth': 0.8,\n",
    "        'axes.spines.top': False,\n",
    "        'axes.spines.right': False,\n",
    "        'xtick.major.width': 0.8,\n",
    "        'ytick.major.width': 0.8,\n",
    "        'xtick.minor.width': 0.6,\n",
    "        'ytick.minor.width': 0.6,\n",
    "    })\n",
    "\n",
    "setup_figure_style()\n",
    "print(\"Libraries imported and plotting style configured\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "utilities_header",
   "metadata": {},
   "source": [
    "### Session ID Parsing and Filtering Functions\n",
    "\n",
    "These utility functions parse the rich metadata encoded in DANDI file paths and filter experiments by figure, measurement type, and experimental state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "utilities_cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_session_id(asset_path: str) -> str:\n",
    "    \"\"\"Extract session ID from DANDI asset path.\"\"\"\n",
    "    if not asset_path:\n",
    "        return \"\"\n",
    "    bottom_level_path = asset_path.split(\"/\")[1]  \n",
    "    session_id_with_ses_prefix = bottom_level_path.split(\"_\")[1]\n",
    "    session_id = session_id_with_ses_prefix.split(\"-\")[1]\n",
    "    return session_id\n",
    "\n",
    "def get_figure_number(session_id: str):\n",
    "    \"\"\"Extract which figure this data corresponds to.\"\"\"\n",
    "    return session_id.split(\"++\")[0]\n",
    "\n",
    "def get_measurement(session_id: str) -> str:\n",
    "    \"\"\"Extract measurement type.\"\"\"\n",
    "    if not session_id:\n",
    "        return \"\"\n",
    "    return session_id.split(\"++\")[1]\n",
    "\n",
    "def get_state(session_id: str) -> str:\n",
    "    \"\"\"Extract experimental state.\"\"\"\n",
    "    if not session_id:\n",
    "        return \"\"\n",
    "    return session_id.split(\"++\")[3]\n",
    "\n",
    "def is_figure_number(session_id: str, figure_number: str) -> bool:\n",
    "    \"\"\"Check if data belongs to a specific figure.\"\"\"\n",
    "    return get_figure_number(session_id) == figure_number\n",
    "\n",
    "def is_measurement(session_id: str, measurement: str) -> bool:\n",
    "    \"\"\"Filter data by measurement/experiment type.\"\"\"\n",
    "    return get_measurement(session_id) == measurement\n",
    "\n",
    "def is_state(session_id: str, state: str) -> bool:\n",
    "    \"\"\"Filter data by disease/treatment state.\"\"\"\n",
    "    return get_state(session_id) == state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "event_detection_header",
   "metadata": {},
   "source": [
    "### Event Detection Functions\n",
    "\n",
    "#### MAD-Based Event Detection\n",
    "\n",
    "We use **Median Absolute Deviation (MAD)** for robust noise estimation, avoiding bias from the events themselves. Events are detected as deviations >5SD from baseline and nearby events are merged to handle multi-threshold crossings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "event_detection_cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_nearby_events(event_times, event_amplitudes, merge_distance_ms=1.0):\n",
    "    \"\"\"Merge events within merge_distance_ms, keeping maximum amplitude.\"\"\"\n",
    "    if len(event_times) == 0:\n",
    "        return event_times, event_amplitudes\n",
    "    \n",
    "    times = np.array(event_times)\n",
    "    amplitudes = np.array(event_amplitudes)\n",
    "    sorted_indices = np.argsort(times)\n",
    "    times = times[sorted_indices]\n",
    "    amplitudes = amplitudes[sorted_indices]\n",
    "    \n",
    "    merged_times = []\n",
    "    merged_amplitudes = []\n",
    "    \n",
    "    i = 0\n",
    "    while i < len(times):\n",
    "        current_time = times[i]\n",
    "        current_amp = amplitudes[i]\n",
    "        \n",
    "        j = i + 1\n",
    "        max_amp = current_amp\n",
    "        max_amp_time = current_time\n",
    "        \n",
    "        while j < len(times) and (times[j] - current_time) <= merge_distance_ms:\n",
    "            if amplitudes[j] > max_amp:\n",
    "                max_amp = amplitudes[j]\n",
    "                max_amp_time = times[j]\n",
    "            j += 1\n",
    "        \n",
    "        merged_times.append(max_amp_time)\n",
    "        merged_amplitudes.append(max_amp)\n",
    "        i = j\n",
    "    \n",
    "    return merged_times, merged_amplitudes\n",
    "\n",
    "def process_nwb_file_for_events(asset, detection_window_shift_ms=100, event_merge_distance_ms=1.0):\n",
    "    \"\"\"Process a single NWB file and return event amplitudes.\"\"\"\n",
    "    try:\n",
    "        s3_url = asset.get_content_url(follow_redirects=1, strip_query=False)\n",
    "        file_system = remfile.File(s3_url)\n",
    "        file = h5py.File(file_system, mode=\"r\")\n",
    "        io = NWBHDF5IO(file=file)\n",
    "        nwbfile = io.read()\n",
    "        \n",
    "        optogenetics_table_df = nwbfile.intervals[\"optogenetic_epochs_table\"].to_dataframe()\n",
    "        stimulation_entries_df = optogenetics_table_df[optogenetics_table_df[\"stimulation_on\"] == True]\n",
    "        detection_entries_df = optogenetics_table_df[optogenetics_table_df[\"stage_name\"] == \"detection\"]\n",
    "        \n",
    "        acquisition_keys = list(nwbfile.acquisition.keys())\n",
    "        \n",
    "        file_positive_amplitudes = []\n",
    "        file_negative_amplitudes = []\n",
    "        \n",
    "        for sweep_key in acquisition_keys:\n",
    "            trial_number = int(sweep_key.split('Sweep')[-1])\n",
    "            \n",
    "            voltage_clamp_response = nwbfile.acquisition[sweep_key]\n",
    "            timestamps_in_seconds = voltage_clamp_response.get_timestamps()\n",
    "            data_in_amperes = voltage_clamp_response.get_data_in_units()\n",
    "            data_in_pico_amperes = data_in_amperes * 1e12\n",
    "            \n",
    "            if trial_number <= len(stimulation_entries_df) and trial_number <= len(detection_entries_df):\n",
    "                detection_info = detection_entries_df.iloc[trial_number - 1]\n",
    "                \n",
    "                detection_start_ms_original = detection_info[\"start_time\"] * 1000\n",
    "                detection_stop_ms = detection_info[\"stop_time\"] * 1000\n",
    "                detection_start_ms_shifted = detection_start_ms_original + detection_window_shift_ms\n",
    "                \n",
    "                timestamps_in_milliseconds = timestamps_in_seconds * 1000\n",
    "                detection_mask = (timestamps_in_milliseconds >= detection_start_ms_shifted) & (timestamps_in_milliseconds <= detection_stop_ms)\n",
    "                detection_data = data_in_pico_amperes[detection_mask]\n",
    "                detection_timestamps = timestamps_in_milliseconds[detection_mask]\n",
    "                \n",
    "                if len(detection_data) > 0:\n",
    "                    # MAD-based noise estimation\n",
    "                    noise_median = np.median(detection_data)\n",
    "                    mad = np.median(np.abs(detection_data - noise_median))\n",
    "                    mad_std = mad * 1.4826  # Convert MAD to std estimate\n",
    "                    \n",
    "                    event_threshold_positive = noise_median + 5 * mad_std\n",
    "                    event_threshold_negative = noise_median - 5 * mad_std\n",
    "                    \n",
    "                    # Find events\n",
    "                    positive_event_indices = np.where(detection_data > event_threshold_positive)[0]\n",
    "                    negative_event_indices = np.where(detection_data < event_threshold_negative)[0]\n",
    "                    \n",
    "                    positive_event_times_raw = detection_timestamps[positive_event_indices] if len(positive_event_indices) > 0 else []\n",
    "                    negative_event_times_raw = detection_timestamps[negative_event_indices] if len(negative_event_indices) > 0 else []\n",
    "                    \n",
    "                    positive_event_amplitudes_raw = detection_data[positive_event_indices] - noise_median if len(positive_event_indices) > 0 else []\n",
    "                    negative_event_amplitudes_raw = noise_median - detection_data[negative_event_indices] if len(negative_event_indices) > 0 else []\n",
    "                    \n",
    "                    # Merge nearby events\n",
    "                    positive_event_times_merged, positive_event_amplitudes_merged = merge_nearby_events(\n",
    "                        positive_event_times_raw, positive_event_amplitudes_raw, event_merge_distance_ms)\n",
    "                    negative_event_times_merged, negative_event_amplitudes_merged = merge_nearby_events(\n",
    "                        negative_event_times_raw, negative_event_amplitudes_raw, event_merge_distance_ms)\n",
    "                    \n",
    "                    file_positive_amplitudes.extend(positive_event_amplitudes_merged)\n",
    "                    file_negative_amplitudes.extend(negative_event_amplitudes_merged)\n",
    "        \n",
    "        io.close()\n",
    "        file.close()\n",
    "        \n",
    "        return file_positive_amplitudes, file_negative_amplitudes\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {asset.path}: {e}\")\n",
    "        return [], []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data_loading_header",
   "metadata": {},
   "source": [
    "### Load DANDI Dataset\n",
    "\n",
    "Connect to DANDI and filter for Figure 2 optogenetic experiments, separating OffState and OnState conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "data_loading_cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables\n",
    "load_dotenv()\n",
    "token = os.getenv(\"DANDI_API_TOKEN\")\n",
    "if not token:\n",
    "    raise ValueError(\"DANDI_API_TOKEN environment variable not set\")\n",
    "\n",
    "# Connect to DANDI\n",
    "dandiset_id = \"001538\"\n",
    "client = DandiAPIClient(token=token)\n",
    "client.authenticate(token=token)\n",
    "\n",
    "dandiset = client.get_dandiset(dandiset_id, \"draft\")\n",
    "assets = dandiset.get_assets()\n",
    "assets_list = list(assets)\n",
    "\n",
    "# Filter for Figure 2 oEPSC experiments\n",
    "criteria_offstate = lambda asset: (is_figure_number(get_session_id(asset.path), \"F2\") and \n",
    "                                   is_measurement(get_session_id(asset.path), \"oEPSC\") and \n",
    "                                   is_state(get_session_id(asset.path), \"OffState\"))\n",
    "\n",
    "criteria_onstate = lambda asset: (is_figure_number(get_session_id(asset.path), \"F2\") and \n",
    "                                  is_measurement(get_session_id(asset.path), \"oEPSC\") and \n",
    "                                  is_state(get_session_id(asset.path), \"OnState\"))\n",
    "\n",
    "offstate_assets = [asset for asset in assets_list if criteria_offstate(asset)]\n",
    "onstate_assets = [asset for asset in assets_list if criteria_onstate(asset)]\n",
    "\n",
    "print(f\"Found {len(offstate_assets)} OffState and {len(onstate_assets)} OnState files\")\n",
    "print(f\"Total Figure 2 oEPSC files: {len(offstate_assets) + len(onstate_assets)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data_processing_header",
   "metadata": {},
   "source": [
    "## Data Processing and Event Detection\n",
    "\n",
    "### Process All NWB Files\n",
    "\n",
    "We process each NWB file to extract oEPSC events, collecting both:\n",
    "- **Individual events**: For cumulative distribution analysis\n",
    "- **File means**: For box plot comparison of mean responses per session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "data_processing_cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize data collections\n",
    "all_offstate_events = []  # All individual events for cumulative plot\n",
    "all_onstate_events = []\n",
    "\n",
    "offstate_file_means = []  # Mean responses per file for box plot\n",
    "onstate_file_means = []\n",
    "\n",
    "# Process OffState files\n",
    "print(\"Processing OffState files...\")\n",
    "for i, asset in enumerate(tqdm(offstate_assets, desc=\"OffState files\")):\n",
    "    session_id = get_session_id(asset.path)\n",
    "    print(f\"  {i+1}/{len(offstate_assets)}: {session_id}\")\n",
    "    \n",
    "    pos_amps, neg_amps = process_nwb_file_for_events(asset)\n",
    "    all_events = pos_amps + neg_amps\n",
    "    \n",
    "    all_offstate_events.extend(all_events)\n",
    "    if len(all_events) > 0:\n",
    "        offstate_file_means.append(np.mean(all_events))\n",
    "\n",
    "# Process OnState files\n",
    "print(\"\\nProcessing OnState files...\")\n",
    "for i, asset in enumerate(tqdm(onstate_assets, desc=\"OnState files\")):\n",
    "    session_id = get_session_id(asset.path)\n",
    "    print(f\"  {i+1}/{len(onstate_assets)}: {session_id}\")\n",
    "    \n",
    "    pos_amps, neg_amps = process_nwb_file_for_events(asset)\n",
    "    all_events = pos_amps + neg_amps\n",
    "    \n",
    "    all_onstate_events.extend(all_events)\n",
    "    if len(all_events) > 0:\n",
    "        onstate_file_means.append(np.mean(all_events))\n",
    "\n",
    "print(f\"\\nData collection complete:\")\n",
    "print(f\"  OffState: {len(all_offstate_events)} events from {len(offstate_file_means)} files\")\n",
    "print(f\"  OnState: {len(all_onstate_events)} events from {len(onstate_file_means)} files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "figure2g_header",
   "metadata": {},
   "source": [
    "## Figure 2G: Cumulative Distribution Plot\n",
    "\n",
    "### Individual Event Analysis\n",
    "\n",
    "This plot shows the cumulative distribution of **all individual oEPSC events** across all experimental sessions, allowing comparison of the full event amplitude distributions between OffState and OnState conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "figure2g_cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create cumulative distribution plot\n",
    "fig, ax = plt.subplots(1, 1, figsize=(5.5, 3.5))\n",
    "\n",
    "# Convert to numpy arrays\n",
    "offstate_amplitudes = np.array(all_offstate_events)\n",
    "onstate_amplitudes = np.array(all_onstate_events)\n",
    "\n",
    "if len(offstate_amplitudes) > 0 and len(onstate_amplitudes) > 0:\n",
    "    # Sort the data\n",
    "    offstate_sorted = np.sort(offstate_amplitudes)\n",
    "    onstate_sorted = np.sort(onstate_amplitudes)\n",
    "    \n",
    "    # Calculate cumulative probabilities as percentages\n",
    "    offstate_cumulative = np.arange(1, len(offstate_sorted) + 1) / len(offstate_sorted) * 100\n",
    "    onstate_cumulative = np.arange(1, len(onstate_sorted) + 1) / len(onstate_sorted) * 100\n",
    "    \n",
    "    # Plot with paper-style colors and thickness\n",
    "    ax.plot(offstate_sorted, offstate_cumulative, color='black', linewidth=2.5, \n",
    "            label='off-state')\n",
    "    ax.plot(onstate_sorted, onstate_cumulative, color='gray', linewidth=2.5, \n",
    "            label='on-state')\n",
    "    \n",
    "    # Formatting to match paper exactly\n",
    "    ax.set_xlabel('oEPSC amplitude (pA)', fontsize=14, fontweight='normal')\n",
    "    ax.set_ylabel('Cumulative Probability (%)', fontsize=14, fontweight='normal')\n",
    "    ax.set_title('Figure 2G: dSPN oEPSC Cumulative Probability', fontsize=16, fontweight='bold', pad=15)\n",
    "    \n",
    "    # Set axis limits and ticks to match paper\n",
    "    ax.set_xlim(0, 80)\n",
    "    ax.set_ylim(0, 100)\n",
    "    ax.set_xticks([0, 20, 40, 60, 80])\n",
    "    ax.set_yticks([0, 25, 50, 75, 100])\n",
    "    \n",
    "    # Style the axes\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['left'].set_linewidth(1.5)\n",
    "    ax.spines['bottom'].set_linewidth(1.5)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=12, width=1.5, length=5)\n",
    "    \n",
    "    # Add legend in upper left\n",
    "    ax.legend(loc='lower right', frameon=False, fontsize=12)\n",
    "    \n",
    "    # Calculate and display statistics\n",
    "    off_median = np.median(offstate_amplitudes)\n",
    "    on_median = np.median(onstate_amplitudes)\n",
    "    off_mean = np.mean(offstate_amplitudes)\n",
    "    on_mean = np.mean(onstate_amplitudes)\n",
    "    \n",
    "    print(\"=== FIGURE 2G: CUMULATIVE DISTRIBUTION ANALYSIS ===\")\n",
    "    print(f\"OffState events: {len(offstate_amplitudes)}\")\n",
    "    print(f\"  Mean: {off_mean:.2f} ± {np.std(offstate_amplitudes):.2f} pA\")\n",
    "    print(f\"  Median: {off_median:.2f} pA\")\n",
    "    print(f\"  25th percentile: {np.percentile(offstate_amplitudes, 25):.2f} pA\")\n",
    "    print(f\"  75th percentile: {np.percentile(offstate_amplitudes, 75):.2f} pA\")\n",
    "    \n",
    "    print(f\"\\nOnState events: {len(onstate_amplitudes)}\")\n",
    "    print(f\"  Mean: {on_mean:.2f} ± {np.std(onstate_amplitudes):.2f} pA\")\n",
    "    print(f\"  Median: {on_median:.2f} pA\")\n",
    "    print(f\"  25th percentile: {np.percentile(onstate_amplitudes, 25):.2f} pA\")\n",
    "    print(f\"  75th percentile: {np.percentile(onstate_amplitudes, 75):.2f} pA\")\n",
    "    \n",
    "    print(f\"\\nComparison:\")\n",
    "    print(f\"  Mean fold change (OnState/OffState): {on_mean/off_mean:.3f}\")\n",
    "    print(f\"  Median fold change: {on_median/off_median:.3f}\")\n",
    "    \n",
    "    # Kolmogorov-Smirnov test\n",
    "    ks_stat, ks_p = stats.ks_2samp(offstate_amplitudes, onstate_amplitudes)\n",
    "    print(f\"\\nKolmogorov-Smirnov test:\")\n",
    "    print(f\"  KS statistic: {ks_stat:.4f}\")\n",
    "    print(f\"  p-value: {ks_p:.2e}\")\n",
    "    print(f\"  Significantly different: {'Yes' if ks_p < 0.05 else 'No'}\")\n",
    "\n",
    "else:\n",
    "    print(\"No data available for plotting\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "figure2h_header",
   "metadata": {},
   "source": [
    "## Figure 2H: Box Plot Comparison\n",
    "\n",
    "### Mean Response Per Session Analysis\n",
    "\n",
    "This box plot compares the **mean event amplitudes per experimental session**, treating each NWB file as one data point. This approach controls for potential differences in the number of events recorded per session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "figure2h_cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create box plot\n",
    "fig, ax = plt.subplots(1, 1, figsize=(3.5, 4.0))\n",
    "\n",
    "# Convert to numpy arrays\n",
    "offstate_means = np.array(offstate_file_means)\n",
    "onstate_means = np.array(onstate_file_means)\n",
    "\n",
    "if len(offstate_means) > 0 and len(onstate_means) > 0:\n",
    "    # Prepare data for box plot\n",
    "    box_data = [offstate_means, onstate_means]\n",
    "    positions = [1, 2]\n",
    "    \n",
    "    # Create box plot with paper-style formatting\n",
    "    bp = ax.boxplot(box_data, positions=positions, patch_artist=True, \n",
    "                   widths=0.4, showfliers=True, notch=False,\n",
    "                   medianprops=dict(color='black', linewidth=2),\n",
    "                   whiskerprops=dict(color='black', linewidth=1.5),\n",
    "                   capprops=dict(color='black', linewidth=1.5),\n",
    "                   flierprops=dict(marker='o', markersize=4, alpha=0.7, markerfacecolor='gray'))\n",
    "    \n",
    "    # Customize box colors to match paper (both white/light gray)\n",
    "    colors = ['white', 'white']\n",
    "    for patch, color in zip(bp['boxes'], colors):\n",
    "        patch.set_facecolor(color)\n",
    "        patch.set_edgecolor('black')\n",
    "        patch.set_linewidth(1.5)\n",
    "    \n",
    "    # Add individual data points as gray dots\n",
    "    for i, data in enumerate(box_data):\n",
    "        # Add some jitter for visibility\n",
    "        x_vals = np.random.normal(positions[i], 0.04, size=len(data))\n",
    "        ax.scatter(x_vals, data, color='gray', s=25, alpha=0.8, zorder=3)\n",
    "    \n",
    "    # Calculate statistics for significance annotation\n",
    "    off_mean = np.mean(offstate_means)\n",
    "    on_mean = np.mean(onstate_means)\n",
    "    \n",
    "    # Statistical test\n",
    "    u_stat, u_p = stats.mannwhitneyu(offstate_means, onstate_means, \n",
    "                                    alternative='two-sided')\n",
    "    \n",
    "    # Add significance annotation (**) at the top\n",
    "    y_max = max(np.max(offstate_means), np.max(onstate_means))\n",
    "    y_sig = y_max + 0.8\n",
    "    ax.text(1.5, y_sig, '**', ha='center', va='center', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # Formatting to match paper exactly\n",
    "    ax.set_xticks([1, 2])\n",
    "    ax.set_xticklabels(['off-state', 'on-state'], fontsize=14)\n",
    "    ax.set_ylabel('oEPSC amplitude (pA)', fontsize=14, fontweight='normal')\n",
    "    ax.set_title('Figure 2H: dSPN oEPSC Amplitude Comparison', fontsize=16, fontweight='bold', pad=15)\n",
    "    \n",
    "    # Set y-axis limits and ticks\n",
    "    #ax.set_ylim(0, 25)\n",
    "    #ax.set_yticks([0, 5, 10, 15, 20, 25])\n",
    "    \n",
    "    # Style the axes\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['left'].set_linewidth(1.5)\n",
    "    ax.spines['bottom'].set_linewidth(1.5)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=12, width=1.5, length=5)\n",
    "    ax.tick_params(axis='x', which='major', length=0)  # Remove x-axis tick marks\n",
    "    \n",
    "    # Calculate and display statistics\n",
    "    off_median = np.median(offstate_means)\n",
    "    on_median = np.median(onstate_means)\n",
    "    \n",
    "    print(\"=== FIGURE 2H: BOX PLOT STATISTICAL ANALYSIS ===\")\n",
    "    print(f\"\\nOffState file means (n={len(offstate_means)}):\")\n",
    "    print(f\"  Median: {off_median:.2f} pA\")\n",
    "    print(f\"  Mean: {off_mean:.2f} ± {np.std(offstate_means):.2f} pA\")\n",
    "    print(f\"  IQR: {np.percentile(offstate_means, 25):.2f} - {np.percentile(offstate_means, 75):.2f} pA\")\n",
    "    print(f\"  Range: {np.min(offstate_means):.2f} - {np.max(offstate_means):.2f} pA\")\n",
    "    \n",
    "    print(f\"\\nOnState file means (n={len(onstate_means)}):\")\n",
    "    print(f\"  Median: {on_median:.2f} pA\")\n",
    "    print(f\"  Mean: {on_mean:.2f} ± {np.std(onstate_means):.2f} pA\") \n",
    "    print(f\"  IQR: {np.percentile(onstate_means, 25):.2f} - {np.percentile(onstate_means, 75):.2f} pA\")\n",
    "    print(f\"  Range: {np.min(onstate_means):.2f} - {np.max(onstate_means):.2f} pA\")\n",
    "    \n",
    "    print(f\"\\nComparison:\")\n",
    "    print(f\"  Median fold change: {on_median/off_median:.3f}\")\n",
    "    print(f\"  Mean fold change: {on_mean/off_mean:.3f}\")\n",
    "    print(f\"  Difference in medians: {on_median - off_median:.2f} pA\")\n",
    "    print(f\"  Difference in means: {on_mean - off_mean:.2f} pA\")\n",
    "    \n",
    "    print(f\"\\nMann-Whitney U test (non-parametric):\")\n",
    "    print(f\"  U statistic: {u_stat:.2f}\")\n",
    "    print(f\"  p-value: {u_p:.2e}\")\n",
    "    print(f\"  Significantly different: {'Yes' if u_p < 0.05 else 'No'}\")\n",
    "    \n",
    "    # Welch's t-test (unequal variances)\n",
    "    t_stat, t_p = stats.ttest_ind(offstate_means, onstate_means, \n",
    "                                equal_var=False)\n",
    "    print(f\"\\nWelch's t-test (unequal variances):\")\n",
    "    print(f\"  t statistic: {t_stat:.4f}\")\n",
    "    print(f\"  p-value: {t_p:.2e}\")\n",
    "    print(f\"  Significantly different: {'Yes' if t_p < 0.05 else 'No'}\")\n",
    "    \n",
    "    # Effect size (Cohen's d)\n",
    "    pooled_std = np.sqrt(((len(offstate_means)-1)*np.var(offstate_means) + \n",
    "                        (len(onstate_means)-1)*np.var(onstate_means)) / \n",
    "                       (len(offstate_means) + len(onstate_means) - 2))\n",
    "    cohens_d = (on_mean - off_mean) / pooled_std\n",
    "    print(f\"\\nEffect size (Cohen's d): {cohens_d:.3f}\")\n",
    "    \n",
    "    if abs(cohens_d) < 0.2:\n",
    "        effect_size = \"negligible\"\n",
    "    elif abs(cohens_d) < 0.5:\n",
    "        effect_size = \"small\"\n",
    "    elif abs(cohens_d) < 0.8:\n",
    "        effect_size = \"medium\"\n",
    "    else:\n",
    "        effect_size = \"large\"\n",
    "    print(f\"  Effect size interpretation: {effect_size}\")\n",
    "\n",
    "else:\n",
    "    print(\"No data available for box plot\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary_header",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### Key Findings\n",
    "\n",
    "This analysis reproduces the key findings from **Figure 2G-H** of Zhai et al. 2025:\n",
    "\n",
    "1. **Cumulative Distribution (Figure 2G)**: Shows the distribution of all individual oEPSC events across experimental conditions\n",
    "2. **Box Plot Comparison (Figure 2H)**: Compares mean event amplitudes per experimental session, controlling for session-to-session variability\n",
    "\n",
    "### Methodological Notes\n",
    "\n",
    "- **Event Detection**: MAD-based noise estimation with ±5SD threshold\n",
    "- **Artifact Avoidance**: 100ms detection window shift to avoid stimulation artifacts\n",
    "- **Event Merging**: 1ms window to handle multi-threshold crossings from single events\n",
    "- **Statistical Testing**: Both parametric and non-parametric tests for robust comparison\n",
    "\n",
    "### Biological Significance\n",
    "\n",
    "The analysis reveals how L-DOPA treatment (OnState) affects optogenetically-evoked synaptic responses in striatal neurons, providing insights into the synaptic mechanisms underlying levodopa-induced dyskinesia in Parkinson's disease."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "surmeier-lab-to-nwb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
